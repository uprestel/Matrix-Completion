\documentclass{article}
\usepackage{blindtext}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\title{Compressed Sensing}
%\author{Ulrich P}
\date{\today}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\Prox}{Prox}
\DeclareMathOperator{\diag}{diag}


\begin{document}

\maketitle

\section{Overview}

Short overwiew of matrix completion:

$$\min ||X||_* \ \ \ s. t. \ \ \ AX = B$$

We need to find the min rank $X$ such that $AX = B$

\section{Douglas- Rachford Splitting}

In the noiseless case we can use DRS to solve this numerically via a fixed-point iteration: 
$$z^{(k+1)} = z^{(k)} + \Prox_{\gamma g}\Big(2 \Prox_{\gamma f}(z^{(k)}) - z^{(k)}\Big) - \Prox_{\gamma g}(z^{(k)})$$
We know that for $f = \delta_C$ with $C = \lbrace X | AX = B \rbrace$ we obtain
\begin{align*}
\Prox_{\gamma f}(x) = \Pi_C(x) &= x + A^+(b-Ax)
\\ &= x + A^T(A A^T)^{-1}(b - Ax)
\\ &= x + A^T(b-Ax)
\end{align*}
and via the SVD
\begin{align*}
\Prox_{\gamma g}(x) &= U S_\delta(\sigma(x))V^T
\\ &= U (\sigma(x) - \gamma)_{+} V^T
\end{align*}


\section{FISTA}

In the noisy case we are trying to minimize the following objective (in the Lagrangian formulation):

$$\min_X \lambda||X||_*  + \frac{1}{2} ||AX - B||_2^2$$

The FISTA algorithm is formulated with respect to the following objective:

$$\min_X f(x) + g(x)$$

where we assume $f$ and $g$ to be sufficiently smooth, i.e. $f \in C^{1,1}(\mathbb{R}^n)$, which means

$$\exists L(f) : ||\nabla f(x) - \nabla f(y)|| \leq L(f)||x - y|| \forall x,y \in \mathbb{R}^n$$

In our case we have $f(x) = \frac{1}{2} ||AX - B||_2^2$ and $g(x) =  \lambda||X||_*$ and by simple calculation: $L(f) = 2\lambda_{\max}(A^TA)$
\begin{algorithm}[H]
\caption{FISTA with constant step size}
\hspace*{\algorithmicindent} \textbf{Input} Lipschitz- constant $L(f)$ of $\nabla f$, $y_1 = x_0 \in \mathbb{R}^n, t_1=1$
\begin{algorithmic}[1]
\For{$k = 1, ...$}                    
	\State {$x_k = p_L(y_k)$}
	\State {$t_{k+1} = \frac{1 + \sqrt{1 + 4*t_k^2}}{2}$}
	\State {$y_{k+1} = x_k + \frac{t_k -1}{t_{k+1}}(x_k - x_{k-1})$}
\EndFor
\end{algorithmic}
\end{algorithm}


In this algorithm we def. 
\begin{align*}
Q_L(x,y) &= f(y) + \langle x-y, \nabla f(y) \rangle + \frac{L(f)}{2} ||x-y||^2 + g(x)\\
p_L(y) &= \argmin_x Q_L(x,y)\\
&= \argmin_x \Big( g(x) + \frac{L(f)}{2} \Big\| x - \Big( y - \frac{1}{L} \nabla f(y)\Big)\Big\|^2 \Big)\\
&= \Prox_{1/L g}(y - \frac{1}{L}\nabla f(y))
\end{align*}
To simplfify this expression further, we examine the the SVD of the input matrix of $p_L$, which we call $B$ for now. It turns out we arrive at a singular value thresholding step: Let $B = U \Sigma V^T = U \diag(\sigma(b)) V^T$ and
$$\Prox_{\lambda g}(B) = U \diag(\sigma(B) - \lambda)_+ V^T$$
which finally reveals $\Prox_{1/L g} \Big(y - \frac{1}{L} \nabla f(y) \Big) = U \diag \Big(\sigma(y - \frac{1}{L} \nabla f(y)) - \frac{1}{L}\Big)_+ V^T$


\textbf{I'm not sure if this is correct}
\end{document}